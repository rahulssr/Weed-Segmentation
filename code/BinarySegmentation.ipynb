{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport os\nimport numpy as np\nimport random\n# import segmentation_models as sm\n\nfrom tqdm import tqdm\nfrom time import sleep\nimport cv2\nimport matplotlib.pyplot as plt\nseed = 42\nfrom keras.layers import Input\nnp.random.seed = seed","metadata":{"execution":{"iopub.status.busy":"2022-06-30T09:39:11.697709Z","iopub.execute_input":"2022-06-30T09:39:11.698379Z","iopub.status.idle":"2022-06-30T09:39:12.428896Z","shell.execute_reply.started":"2022-06-30T09:39:11.698344Z","shell.execute_reply":"2022-06-30T09:39:12.427912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip3 install -U segmentation-models","metadata":{"execution":{"iopub.status.busy":"2022-06-30T09:35:52.891279Z","iopub.execute_input":"2022-06-30T09:35:52.891613Z","iopub.status.idle":"2022-06-30T09:38:22.094718Z","shell.execute_reply.started":"2022-06-30T09:35:52.891586Z","shell.execute_reply":"2022-06-30T09:38:22.093596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%reload_ext tensorboard","metadata":{"execution":{"iopub.status.busy":"2022-04-21T23:23:50.073144Z","iopub.execute_input":"2022-04-21T23:23:50.073417Z","iopub.status.idle":"2022-04-21T23:23:50.079651Z","shell.execute_reply.started":"2022-04-21T23:23:50.073385Z","shell.execute_reply":"2022-04-21T23:23:50.078792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from skimage.io import imread, imshow\nfrom skimage.transform import resize","metadata":{"execution":{"iopub.status.busy":"2022-06-30T09:39:16.238987Z","iopub.execute_input":"2022-06-30T09:39:16.239333Z","iopub.status.idle":"2022-06-30T09:39:17.045449Z","shell.execute_reply.started":"2022-06-30T09:39:16.239306Z","shell.execute_reply":"2022-06-30T09:39:17.044465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## tqdm demo\nnumber_list = list(range(100))\nfor x in tqdm(number_list):\n    sleep(0.05)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_WIDTH = 256\nIMG_HEIGHT = 256\nIMG_CHANNELS = 3","metadata":{"execution":{"iopub.status.busy":"2022-06-30T09:39:18.252315Z","iopub.execute_input":"2022-06-30T09:39:18.252922Z","iopub.status.idle":"2022-06-30T09:39:18.258078Z","shell.execute_reply.started":"2022-06-30T09:39:18.252884Z","shell.execute_reply":"2022-06-30T09:39:18.256977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SIZE_X = 256\nSIZE_Y = 256","metadata":{"execution":{"iopub.status.busy":"2022-06-30T09:39:19.575178Z","iopub.execute_input":"2022-06-30T09:39:19.575543Z","iopub.status.idle":"2022-06-30T09:39:19.580004Z","shell.execute_reply.started":"2022-06-30T09:39:19.575513Z","shell.execute_reply":"2022-06-30T09:39:19.578886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_PATH = '../input/seg-true/imagess'\n# TEST_PATH = '../input/weed-detection-and-segmentation/test'\n","metadata":{"execution":{"iopub.status.busy":"2022-06-30T09:39:20.73593Z","iopub.execute_input":"2022-06-30T09:39:20.736338Z","iopub.status.idle":"2022-06-30T09:39:20.741788Z","shell.execute_reply.started":"2022-06-30T09:39:20.736309Z","shell.execute_reply":"2022-06-30T09:39:20.740588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ids = next(os.walk(TRAIN_PATH))[1]\n# test_ids = next(os.walk(TEST_PATH))[1]","metadata":{"execution":{"iopub.status.busy":"2022-06-30T09:39:22.46425Z","iopub.execute_input":"2022-06-30T09:39:22.464604Z","iopub.status.idle":"2022-06-30T09:39:22.497922Z","shell.execute_reply.started":"2022-06-30T09:39:22.464574Z","shell.execute_reply":"2022-06-30T09:39:22.496989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ids","metadata":{"execution":{"iopub.status.busy":"2022-06-30T09:39:23.755634Z","iopub.execute_input":"2022-06-30T09:39:23.756644Z","iopub.status.idle":"2022-06-30T09:39:23.768583Z","shell.execute_reply.started":"2022-06-30T09:39:23.756611Z","shell.execute_reply":"2022-06-30T09:39:23.767427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ids","metadata":{"execution":{"iopub.status.busy":"2022-04-21T09:11:10.421854Z","iopub.execute_input":"2022-04-21T09:11:10.422139Z","iopub.status.idle":"2022-04-21T09:11:10.428646Z","shell.execute_reply.started":"2022-04-21T09:11:10.422108Z","shell.execute_reply":"2022-04-21T09:11:10.427733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype = np.uint8)\nY_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype = np.bool)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T09:39:39.613823Z","iopub.execute_input":"2022-06-30T09:39:39.614575Z","iopub.status.idle":"2022-06-30T09:39:39.621559Z","shell.execute_reply.started":"2022-06-30T09:39:39.614538Z","shell.execute_reply":"2022-06-30T09:39:39.620407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Resizing training images and mask')\nfor n, id_ in tqdm(enumerate(train_ids), total = len(train_ids)):\n    path = TRAIN_PATH + '/' + id_ # stage1/train + id\n    print(path)\n    img = imread(path + '/im/' + id_ + '.jpg')[:,:,:IMG_CHANNELS]\n    # take everything in dimension 1, everything in dimension 2 and 0 to IMG_CHANNELS in dimension 3\n    img = resize(img ,(IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    X_train[n] = img # fill empty X_train with values from img\n    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n    for mask_file in next(os.walk(path + '/masks/'))[2]:\n        mask_ = imread(path + '/masks/' + mask_file)\n        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True), axis = -1)\n    \n        mask = np.maximum(mask, mask_)\n    Y_train[n] = mask\n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-30T09:39:47.649344Z","iopub.execute_input":"2022-06-30T09:39:47.650394Z","iopub.status.idle":"2022-06-30T09:43:35.961912Z","shell.execute_reply.started":"2022-06-30T09:39:47.650347Z","shell.execute_reply":"2022-06-30T09:43:35.957511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"../input/weed-seg/imagess/121/masks/121.jpeg\n../input/weed-seg/imagess/121/masks/121.jpeg","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Resizing training images and mask')\nfor n, id_ in tqdm(enumerate(train_ids), total = len(train_ids)):\n    path = TRAIN_PATH + '/' + id_ # stage1/train + id\n    print(path)\n    img = imread(path + '/im/' + id_ + '.jpg')[:,:,:3]\n    # take everything in dimension 1, everything in dimension 2 and 0 to IMG_CHANNELS in dimension 3\n    img = resize(img ,(SIZE_X, SIZE_Y,3), mode='constant', preserve_range=True)\n    X_train[n] = img # fill empty X_train with values from img\n    mask = np.zeros((SIZE_X, SIZE_Y,3), dtype=np.bool)\n    for mask_file in next(os.walk(path + '/masks/'))[2]:\n        mask_ = imread(path + '/masks/' + mask_file)\n        mask_ = np.expand_dims(resize(mask_, (SIZE_X, SIZE_Y), mode='constant', preserve_range=True), axis=0)\n    \n        mask = np.maximum(mask, mask_)\n    Y_train[n] = mask","metadata":{"execution":{"iopub.status.busy":"2022-06-30T09:39:44.221349Z","iopub.execute_input":"2022-06-30T09:39:44.221727Z","iopub.status.idle":"2022-06-30T09:39:44.561407Z","shell.execute_reply.started":"2022-06-30T09:39:44.221693Z","shell.execute_reply":"2022-06-30T09:39:44.560072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train= np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n# sizes_train = []\n\n# for n, id_ in tqdm(enumerate(train_ids), total = len(train_ids)):\n#     path = TRAIN_PATH + id_ # stage1/train + id\n#     img = imread(path + '/im/' + id_ + '.jpg')[:,:,:IMG_CHANNELS]# take everything in dimension 1, everything in dimension 2 and 0 to IMG_CHANNELS in dimension 3\n#     sizes_train.append([img.shape[0], img.shape[1]])\n#     img = resize(img ,(IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n#     X_train[n] = img # fill empty X_train with values from img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test images\n\nX_test= np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\nsizes_test = []\n\nfor n, id_ in tqdm(enumerate(test_ids), total = len(test_ids)):\n    path = TEST_PATH + '/' + id_ # stage1/train + id\n    img = imread(path + '/im/' + id_ + '.jpg')[:,:,:IMG_CHANNELS]# take everything in dimension 1, everything in dimension 2 and 0 to IMG_CHANNELS in dimension 3\n    sizes_test.append([img.shape[0], img.shape[1]])\n    img = resize(img ,(IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    X_test[n] = img # fill empty X_train with values from img\n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-21T22:25:45.08627Z","iopub.execute_input":"2022-04-21T22:25:45.086554Z","iopub.status.idle":"2022-04-21T22:26:00.894761Z","shell.execute_reply.started":"2022-04-21T22:25:45.086522Z","shell.execute_reply":"2022-04-21T22:26:00.893987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_x = random.randint(0, len(train_ids))\nimshow(X_train[image_x])\nplt.show()\nimshow(np.squeeze(Y_train[image_x]))\nplt.imshow","metadata":{"execution":{"iopub.status.busy":"2022-06-24T16:48:50.872825Z","iopub.execute_input":"2022-06-24T16:48:50.873331Z","iopub.status.idle":"2022-06-24T16:48:51.239199Z","shell.execute_reply.started":"2022-06-24T16:48:50.873283Z","shell.execute_reply":"2022-06-24T16:48:51.236052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = np.array([1, 2])\nx.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-21T09:39:18.019222Z","iopub.execute_input":"2022-04-21T09:39:18.019529Z","iopub.status.idle":"2022-04-21T09:39:18.028Z","shell.execute_reply.started":"2022-04-21T09:39:18.019496Z","shell.execute_reply":"2022-04-21T09:39:18.027076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-21T09:39:29.705384Z","iopub.execute_input":"2022-04-21T09:39:29.705683Z","iopub.status.idle":"2022-04-21T09:39:29.71245Z","shell.execute_reply.started":"2022-04-21T09:39:29.705651Z","shell.execute_reply":"2022-04-21T09:39:29.711071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = np.expand_dims(x, axis=0)\ny","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"z = np.expand_dims(x, axis=-1)\nz.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = tf.keras.layers.Input((IMG_WIDTH , IMG_HEIGHT, IMG_CHANNELS))\n \n# contraction  \n# inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\ns = inputs\n# s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs) # divide each x by 255\nc1 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\nc1 = tf.keras.layers.Dropout(0.1)(c1)\nc1 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n\np1 = tf.keras.layers.MaxPooling2D((2,2))(c1)\nc2 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\nc2 = tf.keras.layers.Dropout(0.1)(c2)                            \nc2 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n\np2 = tf.keras.layers.MaxPooling2D((2,2))(c2)\nc3 = tf.keras.layers.Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\nc3 = tf.keras.layers.Dropout(0.1)(c3)                            \nc3 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n                               \np3 = tf.keras.layers.MaxPooling2D((2,2))(c3)\nc4 = tf.keras.layers.Conv2D(512, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\nc4 = tf.keras.layers.Dropout(0.1)(c4)                            \nc4 = tf.keras.layers.Conv2D(512, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n                            \np4 = tf.keras.layers.MaxPooling2D((2,2))(c4)\nc5 = tf.keras.layers.Conv2D(1024, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\nc5 = tf.keras.layers.Dropout(0.1)(c5)                            \nc5 = tf.keras.layers.Conv2D(1024, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n                            \n# expansion path\n                            \nu6 = tf.keras.layers.Conv2DTranspose(512, (2,2), strides=(2,2), padding='same')(c5)\nu6 = tf.keras.layers.concatenate([u6, c4])\nc6 = tf.keras.layers.Conv2D(512, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\nc6 = tf.keras.layers.Dropout(0.2)(c6)          \nc6 = tf.keras.layers.Conv2D(512, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n\nu7 = tf.keras.layers.Conv2DTranspose(256, (2,2), strides=(2,2), padding='same')(c6)\nu7 = tf.keras.layers.concatenate([u7, c3])\nc7 = tf.keras.layers.Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\nc7 = tf.keras.layers.Dropout(0.2)(c7)          \nc7 = tf.keras.layers.Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)          \n                            \nu8 = tf.keras.layers.Conv2DTranspose(128, (2,2), strides=(2,2), padding='same')(c7)\nu8 = tf.keras.layers.concatenate([u8, c2])\nc8 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\nc8 = tf.keras.layers.Dropout(0.2)(c8)          \nc8 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)                             \n                            \nu9 = tf.keras.layers.Conv2DTranspose(64, (2,2), strides=(2,2), padding='same')(c8)\nu9 = tf.keras.layers.concatenate([u9, c1], axis = 3)\nc9 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\nc9 = tf.keras.layers.Dropout(0.2)(c9)          \nc9 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)   \n                            \n#                       sm.metrics.FScore(threshold=0.5)       \noutputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n# metrics = [sm.metrics.IOUScore(threshold=0.5),sm.metrics.FScore(threshold=0.5)]\nmodel = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=metrics)\n# model.summary()                            \n                            \n                            \n                            \n# strategy = tf.distribute.MirroredStrategy()\n\n# # Then build your model within the strategy context:\n# with strategy.scope():\n# #     model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n# model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n# # model.compile(optimizer='adam', loss='binary_crossentropy', metrics=metrics)\n# model.summary()    \n# # You can then train your model as usual\nmodel.summary()   \n","metadata":{"execution":{"iopub.status.busy":"2022-06-30T09:55:43.171327Z","iopub.execute_input":"2022-06-30T09:55:43.171696Z","iopub.status.idle":"2022-06-30T09:55:43.40472Z","shell.execute_reply.started":"2022-06-30T09:55:43.171648Z","shell.execute_reply":"2022-06-30T09:55:43.403733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_classes = 5","metadata":{"execution":{"iopub.status.busy":"2022-05-06T18:42:36.047681Z","iopub.execute_input":"2022-05-06T18:42:36.048247Z","iopub.status.idle":"2022-05-06T18:42:36.051602Z","shell.execute_reply.started":"2022-05-06T18:42:36.048205Z","shell.execute_reply":"2022-05-06T18:42:36.050833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n\n\n\n\n################################################################\ndef multi_unet_model(n_classes=5, IMG_HEIGHT=256, IMG_WIDTH=256, IMG_CHANNELS=3):\n#Build the model\n    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n    #s = Lambda(lambda x: x / 255)(inputs)   #No need for this if we normalize our inputs beforehand\n    s = inputs\n\n    #Contraction path\n    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n    c1 = Dropout(0.1)(c1)\n    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n    p1 = MaxPooling2D((2, 2))(c1)\n    \n    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n    c2 = Dropout(0.1)(c2)\n    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n    p2 = MaxPooling2D((2, 2))(c2)\n     \n    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n    c3 = Dropout(0.2)(c3)\n    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n    p3 = MaxPooling2D((2, 2))(c3)\n     \n    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n    c4 = Dropout(0.2)(c4)\n    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n     \n    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n    c5 = Dropout(0.3)(c5)\n    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n    \n    #Expansive path \n    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n    u6 = concatenate([u6, c4])\n    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n    c6 = Dropout(0.2)(c6)\n    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n     \n    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n    u7 = concatenate([u7, c3])\n    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n    c7 = Dropout(0.2)(c7)\n    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n     \n    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n    u8 = concatenate([u8, c2])\n    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n    c8 = Dropout(0.1)(c8)\n    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n     \n    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n    u9 = concatenate([u9, c1], axis=3)\n    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n    c9 = Dropout(0.1)(c9)\n    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n     \n    outputs = Conv2D(n_classes, (1, 1), activation='softmax')(c9)\n     \n    model = Model(inputs=[inputs], outputs=[outputs])\n    \n    #NOTE: Compile the model in the main program to make it easy to test with various loss functions\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n    \n    model.summary()\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-06T18:39:30.958359Z","iopub.execute_input":"2022-05-06T18:39:30.958694Z","iopub.status.idle":"2022-05-06T18:39:30.98197Z","shell.execute_reply.started":"2022-05-06T18:39:30.958658Z","shell.execute_reply":"2022-05-06T18:39:30.981008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n    #s = Lambda(lambda x: x / 255)(inputs)   #No need for this if we normalize our inputs beforehand\ns = inputs\n    #Contraction path\nc1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\nc1 = Dropout(0.1)(c1)\nc1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\np1 = MaxPooling2D((2, 2))(c1)\n\nc2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\nc2 = Dropout(0.1)(c2)\nc2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\np2 = MaxPooling2D((2, 2))(c2)\n     \nc3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\nc3 = Dropout(0.2)(c3)\nc3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\np3 = MaxPooling2D((2, 2))(c3)\n     \nc4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\nc4 = Dropout(0.2)(c4)\nc4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\np4 = MaxPooling2D(pool_size=(2, 2))(c4)\n     \nc5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\nc5 = Dropout(0.3)(c5)\nc5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n    \n    #Expansive path \nu6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\nu6 = concatenate([u6, c4])\nc6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\nc6 = Dropout(0.2)(c6)\nc6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n     \nu7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\nu7 = concatenate([u7, c3])\nc7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\nc7 = Dropout(0.2)(c7)\nc7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n     \nu8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\nu8 = concatenate([u8, c2])\nc8= Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\nc8 = Dropout(0.1)(c8)\nc8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n     \nu9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\nu9 = concatenate([u9, c1], axis=3)\nc9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\nc9 = Dropout(0.1)(c9)\nc9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n     \noutputs = Conv2D(n_classes, (1, 1), activation='softmax')(c9)\n     \nmodel = Model(inputs=[inputs], outputs=[outputs])\n    \n    #NOTE: Compile the model in the main program to make it easy to test with various loss functions\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n    \nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T18:53:15.358619Z","iopub.execute_input":"2022-05-06T18:53:15.359039Z","iopub.status.idle":"2022-05-06T18:53:15.768827Z","shell.execute_reply.started":"2022-05-06T18:53:15.359002Z","shell.execute_reply":"2022-05-06T18:53:15.768135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T09:51:45.093076Z","iopub.execute_input":"2022-06-30T09:51:45.094015Z","iopub.status.idle":"2022-06-30T09:51:45.118938Z","shell.execute_reply.started":"2022-06-30T09:51:45.093961Z","shell.execute_reply":"2022-06-30T09:51:45.117177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model checkpoint\ncheckpointer = tf.keras.callbacks.ModelCheckpoint('model_for_weed.h5', verbose = 1, save_best_only=True)\n\ncallbacks = [\n    \n    tf.keras.callbacks.TensorBoard(log_dir='logs')\n]","metadata":{"execution":{"iopub.status.busy":"2022-06-30T09:55:50.673669Z","iopub.execute_input":"2022-06-30T09:55:50.674283Z","iopub.status.idle":"2022-06-30T09:55:51.129756Z","shell.execute_reply.started":"2022-06-30T09:55:50.674248Z","shell.execute_reply":"2022-06-30T09:55:51.124621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = model.fit(X_train, Y_train, validation_split=0.1, batch_size = 8, epochs=100, callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T09:55:54.376513Z","iopub.execute_input":"2022-06-30T09:55:54.377219Z","iopub.status.idle":"2022-06-30T10:03:17.776865Z","shell.execute_reply.started":"2022-06-30T09:55:54.377183Z","shell.execute_reply":"2022-06-30T10:03:17.775815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preds_test = model.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('/kaggle/working/modelb.h5')","metadata":{"execution":{"iopub.status.busy":"2022-06-30T10:09:09.593852Z","iopub.execute_input":"2022-06-30T10:09:09.594195Z","iopub.status.idle":"2022-06-30T10:09:10.111317Z","shell.execute_reply.started":"2022-06-30T10:09:09.594169Z","shell.execute_reply":"2022-06-30T10:09:10.110348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# imshow(preds_test)\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predictions\npreds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\n# preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\n# preds_test = model.predict(X_test, verbose=1)\n\n# pred_test_wh = cv2.threshold(preds_test, 128, 255, cv2.THRESH_BINARY)\npreds_train_t = (preds_train > 0.5).astype(np.uint8)\n# preds_val_t = (preds_val > 0.5).astype(np.uint8)\n# preds_test_t = (preds_test > 0.5).astype(np.uint8)\n\n\n# Perform a sanity check on some random training samples\nix = random.randint(0, len(preds_train))\nimshow(X_train[ix])\nplt.show()\n# imshow(np.squeeze(Y_train[ix]))\n# plt.show()\nimshow(np.squeeze(preds_train[ix]))\nplt.show()\n\n\n# Perform a sanity check on some random validation samples\nix = random.randint(0, len(preds_val_t))\nimshow(X_train[int(X_train.shape[0]*0.9):][ix])\nplt.show()\nimshow(np.squeeze(Y_train[int(Y_train.shape[0]*0.9):][ix]))\nplt.show()\nimshow(np.squeeze(preds_val[ix]))\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-06-30T10:04:43.067143Z","iopub.execute_input":"2022-06-30T10:04:43.067527Z","iopub.status.idle":"2022-06-30T10:04:45.064091Z","shell.execute_reply.started":"2022-06-30T10:04:43.067494Z","shell.execute_reply":"2022-06-30T10:04:45.06258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tensorboard --logdir=logs","metadata":{"execution":{"iopub.status.busy":"2022-06-30T10:05:31.599052Z","iopub.execute_input":"2022-06-30T10:05:31.599993Z","iopub.status.idle":"2022-06-30T10:05:31.607038Z","shell.execute_reply.started":"2022-06-30T10:05:31.599955Z","shell.execute_reply":"2022-06-30T10:05:31.605493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%tensorboard --logdir logs\n","metadata":{"execution":{"iopub.status.busy":"2022-06-30T10:05:34.303481Z","iopub.execute_input":"2022-06-30T10:05:34.30388Z","iopub.status.idle":"2022-06-30T10:05:34.31175Z","shell.execute_reply.started":"2022-06-30T10:05:34.303846Z","shell.execute_reply":"2022-06-30T10:05:34.310042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%tensorboard --logdir logs/val\n","metadata":{"execution":{"iopub.status.busy":"2022-06-30T10:05:01.289867Z","iopub.execute_input":"2022-06-30T10:05:01.29021Z","iopub.status.idle":"2022-06-30T10:05:01.29608Z","shell.execute_reply.started":"2022-06-30T10:05:01.290183Z","shell.execute_reply":"2022-06-30T10:05:01.294805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import datetime\n%load_ext tensorboard\nlog_dir = \"log/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T10:23:26.133155Z","iopub.execute_input":"2022-06-30T10:23:26.133526Z","iopub.status.idle":"2022-06-30T10:23:26.44633Z","shell.execute_reply.started":"2022-06-30T10:23:26.133496Z","shell.execute_reply":"2022-06-30T10:23:26.445323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%tensorboard --logdir log\n","metadata":{"execution":{"iopub.status.busy":"2022-06-30T10:23:31.000142Z","iopub.execute_input":"2022-06-30T10:23:31.0008Z","iopub.status.idle":"2022-06-30T10:23:34.575117Z","shell.execute_reply.started":"2022-06-30T10:23:31.000768Z","shell.execute_reply":"2022-06-30T10:23:34.573721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%tensorboard --logdir logs --bind_all","metadata":{"execution":{"iopub.status.busy":"2022-06-30T10:06:28.592153Z","iopub.execute_input":"2022-06-30T10:06:28.593265Z","iopub.status.idle":"2022-06-30T10:06:28.599093Z","shell.execute_reply.started":"2022-06-30T10:06:28.593216Z","shell.execute_reply":"2022-06-30T10:06:28.597854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.savefig(“file_name.png”)","metadata":{},"execution_count":null,"outputs":[]}]}