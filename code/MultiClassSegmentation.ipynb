{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        break","metadata":{"execution":{"iopub.status.busy":"2022-06-23T16:09:20.248056Z","iopub.execute_input":"2022-06-23T16:09:20.248324Z","iopub.status.idle":"2022-06-23T16:09:20.425853Z","shell.execute_reply.started":"2022-06-23T16:09:20.248295Z","shell.execute_reply":"2022-06-23T16:09:20.424655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Step 1: Load libraries for the U-net Model\nimport numpy as np \nimport os\nimport skimage.io as io\nimport skimage.transform as trans\nimport numpy as np\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom tensorflow.keras import backend as keras\n#from tensorflow import keras\nimport tensorflow as tf","metadata":{"id":"a6KZopJaN3sN","execution":{"iopub.status.busy":"2022-06-29T18:37:43.913968Z","iopub.execute_input":"2022-06-29T18:37:43.914509Z","iopub.status.idle":"2022-06-29T18:37:51.138212Z","shell.execute_reply.started":"2022-06-29T18:37:43.914427Z","shell.execute_reply":"2022-06-29T18:37:51.137433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip3 install -U segmentation-models\n\n\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport segmentation_models as sm","metadata":{"execution":{"iopub.status.busy":"2022-06-29T18:37:51.139841Z","iopub.execute_input":"2022-06-29T18:37:51.140109Z","iopub.status.idle":"2022-06-29T18:38:04.584934Z","shell.execute_reply.started":"2022-06-29T18:37:51.140058Z","shell.execute_reply":"2022-06-29T18:38:04.584149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '../input/support/model_depth_3 (2).py'","metadata":{"execution":{"iopub.status.busy":"2022-06-05T09:03:39.64595Z","iopub.execute_input":"2022-06-05T09:03:39.646197Z","iopub.status.idle":"2022-06-05T09:03:39.652173Z","shell.execute_reply.started":"2022-06-05T09:03:39.64616Z","shell.execute_reply":"2022-06-05T09:03:39.650863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Step 2: Import the U-net model\n# from path import *\nimg_size=(512,512)","metadata":{"id":"bxtoIUN_OKOz","execution":{"iopub.status.busy":"2022-06-29T18:38:04.586552Z","iopub.execute_input":"2022-06-29T18:38:04.588851Z","iopub.status.idle":"2022-06-29T18:38:04.59271Z","shell.execute_reply.started":"2022-06-29T18:38:04.58882Z","shell.execute_reply":"2022-06-29T18:38:04.592052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_class=3","metadata":{"id":"pZNGmJr0OM8l","execution":{"iopub.status.busy":"2022-06-29T18:38:04.595414Z","iopub.execute_input":"2022-06-29T18:38:04.59574Z","iopub.status.idle":"2022-06-29T18:38:04.601076Z","shell.execute_reply.started":"2022-06-29T18:38:04.595709Z","shell.execute_reply":"2022-06-29T18:38:04.6Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Step 3:Define functions for pre-processing data\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport skimage.io as io\nimport skimage.transform as trans\nimport matplotlib.pyplot as plt\nimport scipy.misc as sc\n\n\ndef trainGenerator(batch_size,train_path,image_folder,mask_folder,aug_dict,image_color_mode = \"grayscale\",\n                    mask_color_mode = \"rgb\",image_save_prefix  = \"image\",mask_save_prefix  = \"mask\",\n                    flag_multi_class = True,n_class = n_class,save_to_dir = None,target_size = img_size,seed = 1):\n    '''\n    can generate image and mask at the same time\n    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n    '''\n    image_datagen = ImageDataGenerator(**aug_dict)\n    mask_datagen = ImageDataGenerator(**aug_dict)\n    image_generator = image_datagen.flow_from_directory(\n        train_path,\n        classes = [image_folder],\n        color_mode = image_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = image_save_prefix,\n        class_mode=None,\n        seed = seed)\n    mask_generator = mask_datagen.flow_from_directory(\n        train_path,\n        classes = [mask_folder],\n        color_mode = mask_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = mask_save_prefix,\n        class_mode=None,\n        seed = seed)\n    train_generator = zip(image_generator, mask_generator)\n    for (img,mask) in train_generator:\n        yield (img,mask)\n    \n\ndef testGenerator(test_path,target_size = img_size,flag_multi_class = True,as_gray = True):\n    files=sorted(os.listdir(test_path))\n    num_image=len(files)\n    for i in range(num_image):\n        img = io.imread(os.path.join(test_path,files[i]),as_gray = True)\n        print(files[i])\n        img = trans.resize(img,target_size)\n        #img = np.reshape(img,img.shape+(1,)) if (not flag_multi_class) else img\n        img = np.reshape(img,(1,)+img.shape)\n        yield img","metadata":{"id":"-K_bqcQ6OynZ","execution":{"iopub.status.busy":"2022-06-29T18:38:04.602752Z","iopub.execute_input":"2022-06-29T18:38:04.603099Z","iopub.status.idle":"2022-06-29T18:38:04.618437Z","shell.execute_reply.started":"2022-06-29T18:38:04.603053Z","shell.execute_reply":"2022-06-29T18:38:04.617714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Step 4: Define function to save the test images\n### draw imgs in labelVisualize and save results in saveResult\ndef saveResult(img_path,save_path,npyfile):\n    files=os.listdir(img_path)\n        \n    for i,item in enumerate(npyfile):\n        img=item\n        for k in range(3):\n            img[:,:,k]=img[:,:,k]/np.ptp(img[:,:,k])\n            \n        img[:,:,1]=(img[:,:,1]>0.5).astype(int) #This threshold of 0.05 can be changed to any number in range [0,1]\n        img[:,:,0]=(img[:,:,0]>0.5).astype(int)\n              \n        io.imsave(os.path.join(save_path, files[i]),img)","metadata":{"id":"4qBS0w-NPNyF","execution":{"iopub.status.busy":"2022-06-29T18:38:04.621141Z","iopub.execute_input":"2022-06-29T18:38:04.621401Z","iopub.status.idle":"2022-06-29T18:38:04.628913Z","shell.execute_reply.started":"2022-06-29T18:38:04.621351Z","shell.execute_reply":"2022-06-29T18:38:04.628176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def SaveResultwImage(img_path,save_path,npyfile,target_size=img_size,flag_multi_class = True,num_class = 2):\n    files=os.listdir(img_path)\n    \n    \n    for i,item in enumerate(npyfile):\n        img=item\n        img[img>0.5]=1\n        img[img<=0.5]=0\n        img[:,:,2]=0\n        \n        I = io.imread(os.path.join(img_path,files[i]), as_gray=True)\n        I = trans.resize(I,target_size)\n        img[:,:,0]=np.true_divide((I+img[:,:,0]),2)\n        img[:,:,1]=np.true_divide((I+img[:,:,1]),2)\n        img[:,:,2]=np.true_divide((I+img[:,:,2]),2)\n        io.imsave(os.path.join(save_path, files[i]),img)    ","metadata":{"id":"9NYkQJQCPQcm","execution":{"iopub.status.busy":"2022-06-29T18:38:04.63053Z","iopub.execute_input":"2022-06-29T18:38:04.63083Z","iopub.status.idle":"2022-06-29T18:38:04.639648Z","shell.execute_reply.started":"2022-06-29T18:38:04.630791Z","shell.execute_reply":"2022-06-29T18:38:04.638906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Step 5: Define functions to evaluate the output\nimport sklearn.metrics as sm\n\ndef get_confusion_matrix_elements(groundtruth_list, predicted_list):\n    \"\"\"returns confusion matrix elements i.e TN, FP, FN, TP as floats\n\tSee example code for helper function definitions\n    \"\"\"\n    tn, fp, fn, tp = sm.confusion_matrix(groundtruth_list, predicted_list,labels=[0,1]).ravel()\n    tn, fp, fn, tp = np.float64(tn), np.float64(fp), np.float64(fn), np.float64(tp)\n\n    return tn, fp, fn, tp\n\ndef get_prec_rec_IoU_accuracy(groundtruth_list, predicted_list):\n    \"\"\"returns precision, recall, IoU and accuracy metrics\n\t\"\"\"\n    tn, fp, fn, tp = get_confusion_matrix_elements(groundtruth_list, predicted_list)\n    \n    total = tp + fp + fn + tn\n    accuracy = (tp + tn) / total\n    prec=tp/(tp+fp)\n    rec=tp/(tp+fn)\n    IoU=tp/(tp+fp+fn)\n    \n    return prec,rec,IoU,accuracy\n\ndef get_f1_score(groundtruth_list, predicted_list):\n    \"\"\"Return f1 score covering edge cases\"\"\"\n\n    tn, fp, fn, tp = get_confusion_matrix_elements(groundtruth_list, predicted_list)\n    \n    f1_score = (2 * tp) / ((2 * tp) + fp + fn)\n\n    return f1_score\n\ndef get_validation_metrics(groundtruth,predicted):\n    \"\"\"Return all output metrics. Input is binary images\"\"\"\n   \n    u,v=np.shape(groundtruth)\n    groundtruth_list=np.reshape(groundtruth,(u*v,))\n    predicted_list=np.reshape(predicted,(u*v,))\n    prec,rec,IoU,acc=get_prec_rec_IoU_accuracy(groundtruth_list, predicted_list)\n    f1_score=get_f1_score(groundtruth_list, predicted_list)\n   # print(\"Precision=\",prec, \"Recall=\",rec, \"IoU=\",IoU, \"acc=\",acc, \"F1=\",f1_score)\n    return prec,rec,IoU,acc,f1_score\n\ndef evalResult(gth_path,npyfile,target_size=img_size,flag_multi_class = False,num_class = 3):\n    files=sorted(os.listdir(gth_path))\n    print(files)\n    prec=0\n    rec=0\n    acc=0\n    IoU=0\n    f1_score=0\n    for i,item in enumerate(npyfile):\n        img = item[:,:,0]\n        gth = io.imread(os.path.join(gth_path,files[i]))\n        gth = trans.resize(gth,target_size)\n        img1=np.array(((img - np.min(img))/np.ptp(img))>0.1).astype(float)\n        gth1=np.array(((gth - np.min(gth))/np.ptp(gth))>0.1).astype(float)\n        p,r,I,a,f=get_validation_metrics(gth1,img1)\n        prec=prec+p\n        rec=rec+r\n        acc=acc+a\n        IoU=IoU+I\n        f1_score=f1_score+f\n    print(\"Precision=\",prec/(i+1), \"Recall=\",rec/(i+1), \"IoU=\",IoU/(i+1), \"acc=\",acc/(i+1), \"F1=\",f1_score/(i+1))    ","metadata":{"id":"kvqcpVMdPS7u","execution":{"iopub.status.busy":"2022-06-29T18:38:04.641082Z","iopub.execute_input":"2022-06-29T18:38:04.641664Z","iopub.status.idle":"2022-06-29T18:38:04.753052Z","shell.execute_reply.started":"2022-06-29T18:38:04.641626Z","shell.execute_reply":"2022-06-29T18:38:04.75092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Step 1: Call to image data generator in keras\ndata_gen_args = dict(rotation_range=0.3,\n                     rescale=1./255,\n                    width_shift_range=0.2,\n                    height_shift_range=0.2,\n                    shear_range=0.1,\n                    zoom_range=[0.7,1],\n                    horizontal_flip=True,\n                    vertical_flip=True,\n                    fill_mode='nearest')\nPATH=r'../input/testing2/dataset_final_less_onion/train'","metadata":{"id":"6-H2JZM2PYMN","execution":{"iopub.status.busy":"2022-06-29T18:38:04.754765Z","iopub.execute_input":"2022-06-29T18:38:04.755004Z","iopub.status.idle":"2022-06-29T18:38:04.763353Z","shell.execute_reply.started":"2022-06-29T18:38:04.754972Z","shell.execute_reply":"2022-06-29T18:38:04.761223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#if not os.path.exists(PATH+'aug'):\n #   os.makedirs(PATH+'aug')\n    \n#if not os.path.exists(PATH+'pred'):\n #   os.makedirs(PATH+'pred')  ","metadata":{"id":"wtJ2nKscPbO6","execution":{"iopub.status.busy":"2022-06-05T09:03:39.831452Z","iopub.execute_input":"2022-06-05T09:03:39.831939Z","iopub.status.idle":"2022-06-05T09:03:39.839138Z","shell.execute_reply.started":"2022-06-05T09:03:39.831899Z","shell.execute_reply":"2022-06-05T09:03:39.838333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data_gen = trainGenerator(3,PATH,r'C:\\Users\\91831\\Desktop\\minor project weed\\rahul_send_nbefore_mid_term_minor_ppt\\Multiclass_girl_video_tutorial_dataset1\\trainimages',r'C:\\Users\\91831\\Desktop\\minor project weed\\rahul_send_nbefore_mid_term_minor_ppt\\Multiclass_girl_video_tutorial_dataset1\\train\\GT',data_gen_args, save_to_dir = None)\n#data_gen=trainGenerator(3, PATH, '/content/drive/My Drive/Multiclass_girl_video_tutorial_dataset/Train/images', '/content/drive/My Drive/Multiclass_girl_video_tutorial_dataset/Train/GT','/content/drive/My Drive/Multiclass_girl_video_tutorial_dataset/',flag_multi_class=True, n_class=n_class, save_to_dir=None, target_size=img_size, seed=1)\n\n\ndata_gen = trainGenerator(12,PATH,'images','GT',data_gen_args, save_to_dir = None)\n","metadata":{"id":"bBifs0FdQJeJ","execution":{"iopub.status.busy":"2022-06-29T18:38:04.767457Z","iopub.execute_input":"2022-06-29T18:38:04.767644Z","iopub.status.idle":"2022-06-29T18:38:04.771918Z","shell.execute_reply.started":"2022-06-29T18:38:04.76762Z","shell.execute_reply":"2022-06-29T18:38:04.771254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfor e in range(5):\n    print('Epoch', e)\n    batches = 0\n    for x_batch, y_batch in data_gen:\n        print(np.max(x_batch))\n        for i in range(0, 2):\n            plt.subplot(330+1 + i)\n            plt.imshow(y_batch[i], cmap=plt.get_cmap('gray'))\n        \n\n        plt.show()\n        \n        break","metadata":{"id":"1Llrt0BwQLv9","outputId":"8382213e-f9fd-423c-fb23-28812dacd241","execution":{"iopub.status.busy":"2022-06-29T18:38:04.773317Z","iopub.execute_input":"2022-06-29T18:38:04.773846Z","iopub.status.idle":"2022-06-29T18:38:11.20646Z","shell.execute_reply.started":"2022-06-29T18:38:04.773811Z","shell.execute_reply":"2022-06-29T18:38:11.204863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport os\nimport skimage.io as io\nimport skimage.transform as trans\nimport numpy as np\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom tensorflow.keras import backend as K\nimport tensorflow as tf\n\n\ndef dice_coef(y_true, y_pred, smooth=1):\n    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n\n\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\n\n\n\n\ndef unet(pretrained_weights = None,input_size=(512,512,1), n_class=3):\n    inputs = tf.keras.Input(shape=input_size)\n    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n    conv1 = BatchNormalization()(conv1)\n    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n    conv1 = BatchNormalization()(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n    conv2 = BatchNormalization()(conv2)\n    conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n    conv2 = BatchNormalization()(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n    conv3 = BatchNormalization()(conv3)\n    conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n    conv3 = BatchNormalization()(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    \n    conv4 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n    conv4 = BatchNormalization()(conv4)\n    conv4 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n    conv4 = BatchNormalization()(conv4)\n    drop4 = Dropout(0.5)(conv4)\n    \n\n    conv5 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(drop4)\n    conv5 = BatchNormalization()(conv5)\n    conv5 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n    conv5 = BatchNormalization()(conv5)\n    drop5 = Dropout(0.5)(conv5)\n    \n\n    up6 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n    merge6 = concatenate([conv3,up6], axis = 3)\n    conv6 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n    conv6 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n    \n\n    up7 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n    merge7 = concatenate([conv2,up7], axis = 3)\n    conv7 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n    conv7 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n    \n\n    up8 = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n    merge8 = concatenate([conv1,up8], axis = 3)\n    conv8 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n    conv8 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n    conv9 = Conv2D(n_class, 1, activation = 'softmax')(conv8)\n\n    model = tf.keras.Model(inputs = inputs, outputs = conv9)\n\n    model.compile(optimizer = Adam(lr = 0.001), loss = ['binary_crossentropy'], metrics = ['accuracy'])\n#     model.compile(optimizer = Adam(lr = 0.0001), loss = [dice_coef_loss], metrics = [dice_coef])\n    \n                            \n                            \n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-29T18:54:53.552245Z","iopub.execute_input":"2022-06-29T18:54:53.552504Z","iopub.status.idle":"2022-06-29T18:54:53.578925Z","shell.execute_reply.started":"2022-06-29T18:54:53.552475Z","shell.execute_reply":"2022-06-29T18:54:53.578262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport os\nimport skimage.io as io\nimport skimage.transform as trans\nimport numpy as np\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom tensorflow.keras import backend as K\nimport tensorflow as tf\n\n\ndef dice_coef(y_true, y_pred, smooth=1):\n    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n\n\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\n\n\n\n\ndef unet(pretrained_weights = None,input_size=(512,512,1), n_class=3):\n    inputs = tf.keras.Input(shape=input_size)\n    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n    conv1 = BatchNormalization()(conv1)\n    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n    conv1 = BatchNormalization()(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n    conv2 = BatchNormalization()(conv2)\n    conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n    conv2 = BatchNormalization()(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n    conv3 = BatchNormalization()(conv3)\n    conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n    conv3 = BatchNormalization()(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    \n    conv4 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n    conv4 = BatchNormalization()(conv4)\n    conv4 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n    conv4 = BatchNormalization()(conv4)\n    drop4 = Dropout(0.5)(conv4)\n    \n\n    conv5 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(drop4)\n    conv5 = BatchNormalization()(conv5)\n    conv5 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n    conv5 = BatchNormalization()(conv5)\n    drop5 = Dropout(0.5)(conv5)\n    \n\n    up6 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n    merge6 = concatenate([conv3,up6], axis = 3)\n    conv6 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n    conv6 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n    \n\n    up7 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n    merge7 = concatenate([conv2,up7], axis = 3)\n    conv7 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n    conv7 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n    \n\n    up8 = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n    merge8 = concatenate([conv1,up8], axis = 3)\n    conv8 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n    conv8 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n    conv9 = Conv2D(1, 1, activation = 'softmax')(conv8)\n    \n    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n    conv1 = BatchNormalization()(conv1)\n    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n    conv1 = BatchNormalization()(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n    conv2 = BatchNormalization()(conv2)\n    conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n    conv2 = BatchNormalization()(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n    conv3 = BatchNormalization()(conv3)\n    conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n    conv3 = BatchNormalization()(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    \n    conv4 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n    conv4 = BatchNormalization()(conv4)\n    conv4 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n    conv4 = BatchNormalization()(conv4)\n    drop4 = Dropout(0.5)(conv4)\n    \n\n    conv5 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(drop4)\n    conv5 = BatchNormalization()(conv5)\n    conv5 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n    conv5 = BatchNormalization()(conv5)\n    drop5 = Dropout(0.5)(conv5)\n    \n\n    up6 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n    merge6 = concatenate([conv3,up6], axis = 3)\n    conv6 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n    conv6 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n    \n\n    up7 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n    merge7 = concatenate([conv2,up7], axis = 3)\n    conv7 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n    conv7 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n    \n\n    up8 = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n    merge8 = concatenate([conv1,up8], axis = 3)\n    conv8 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n    conv8 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n    conv9 = Conv2D(n_class, 1, activation = 'softmax')(conv8)\n\n    model = tf.keras.Model(inputs = inputs, outputs = conv9)\n\n    model.compile(optimizer = Adam(lr = 0.001), loss = ['binary_crossentropy'], metrics = ['accuracy'])\n#     model.compile(optimizer = Adam(lr = 0.0001), loss = [dice_coef_loss], metrics = [dice_coef])\n    \n    \n                            \n                            \n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-29T18:48:20.407204Z","iopub.execute_input":"2022-06-29T18:48:20.407504Z","iopub.status.idle":"2022-06-29T18:48:20.44749Z","shell.execute_reply.started":"2022-06-29T18:48:20.407473Z","shell.execute_reply":"2022-06-29T18:48:20.446799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_WIDTH = 512\nIMG_HEIGHT = 512\nIMG_CHANNELS = 1\ninputs = tf.keras.layers.Input((IMG_WIDTH , IMG_HEIGHT, IMG_CHANNELS))\n \n# contraction  \n# inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\ns = inputs\n# s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs) # divide each x by 255\nc1 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\nc1 = tf.keras.layers.Dropout(0.1)(c1)\nc1 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n\np1 = tf.keras.layers.MaxPooling2D((2,2))(c1)\nc2 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\nc2 = tf.keras.layers.Dropout(0.1)(c2)                            \nc2 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n\np2 = tf.keras.layers.MaxPooling2D((2,2))(c2)\nc3 = tf.keras.layers.Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\nc3 = tf.keras.layers.Dropout(0.1)(c3)                            \nc3 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n                               \np3 = tf.keras.layers.MaxPooling2D((2,2))(c3)\nc4 = tf.keras.layers.Conv2D(512, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\nc4 = tf.keras.layers.Dropout(0.1)(c4)                            \nc4 = tf.keras.layers.Conv2D(512, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n                            \np4 = tf.keras.layers.MaxPooling2D((2,2))(c4)\nc5 = tf.keras.layers.Conv2D(1024, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\nc5 = tf.keras.layers.Dropout(0.1)(c5)                            \nc5 = tf.keras.layers.Conv2D(1024, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n                            \n# expansion path\n                            \nu6 = tf.keras.layers.Conv2DTranspose(512, (2,2), strides=(2,2), padding='same')(c5)\nu6 = tf.keras.layers.concatenate([u6, c4])\nc6 = tf.keras.layers.Conv2D(512, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\nc6 = tf.keras.layers.Dropout(0.2)(c6)          \nc6 = tf.keras.layers.Conv2D(512, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n\nu7 = tf.keras.layers.Conv2DTranspose(256, (2,2), strides=(2,2), padding='same')(c6)\nu7 = tf.keras.layers.concatenate([u7, c3])\nc7 = tf.keras.layers.Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\nc7 = tf.keras.layers.Dropout(0.2)(c7)          \nc7 = tf.keras.layers.Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)          \n                            \nu8 = tf.keras.layers.Conv2DTranspose(128, (2,2), strides=(2,2), padding='same')(c7)\nu8 = tf.keras.layers.concatenate([u8, c2])\nc8 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\nc8 = tf.keras.layers.Dropout(0.2)(c8)          \nc8 = tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)                             \n                            \nu9 = tf.keras.layers.Conv2DTranspose(64, (2,2), strides=(2,2), padding='same')(c8)\nu9 = tf.keras.layers.concatenate([u9, c1], axis = 3)\nc9 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\nc9 = tf.keras.layers.Dropout(0.2)(c9)          \nc9 = tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)   \n                            \n#                       sm.metrics.FScore(threshold=0.5)       \noutputs = tf.keras.layers.Conv2D(1, (1, 1), activation='softmax')(c9)\n# metrics = [sm.metrics.IOUScore(threshold=0.5),sm.metrics.FScore(threshold=0.5)]\nmodel = tf.keras.Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=\"accuracy\")\nmodel.summary()                            \n                            \n                            \n                            \n# strategy = tf.distribute.MirroredStrategy()\n\n# # Then build your model within the strategy context:\n# with strategy.scope():\n# #     model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n# model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n\n# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n# # model.compile(optimizer='adam', loss='binary_crossentropy', metrics=metrics)\n# model.summary()    \n# # You can then train your model as usual\n# model.summary()   ","metadata":{"execution":{"iopub.status.busy":"2022-06-27T21:06:00.900335Z","iopub.execute_input":"2022-06-27T21:06:00.900605Z","iopub.status.idle":"2022-06-27T21:06:01.200694Z","shell.execute_reply.started":"2022-06-27T21:06:00.900574Z","shell.execute_reply":"2022-06-27T21:06:01.200035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Step 2: Initialize the model. Train from scratch!\nmodel = unet()\nmodel.summary()","metadata":{"id":"9RXo83U9QR62","outputId":"3671ee15-33fa-4b7d-a3ca-5d83406b5ce8","execution":{"iopub.status.busy":"2022-06-29T18:55:00.166761Z","iopub.execute_input":"2022-06-29T18:55:00.167023Z","iopub.status.idle":"2022-06-29T18:55:00.433595Z","shell.execute_reply.started":"2022-06-29T18:55:00.166995Z","shell.execute_reply":"2022-06-29T18:55:00.432883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Step 3: Initialize Tensorboard to monitor changes in Model Loss \nimport datetime\n%load_ext tensorboard\nlog_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)","metadata":{"id":"QnhKiGe9Q4Au","execution":{"iopub.status.busy":"2022-06-29T18:55:03.917839Z","iopub.execute_input":"2022-06-29T18:55:03.918138Z","iopub.status.idle":"2022-06-29T18:55:04.201703Z","shell.execute_reply.started":"2022-06-29T18:55:03.918109Z","shell.execute_reply":"2022-06-29T18:55:04.200526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualize on tensorboard (move this above)\n%tensorboard --logdir logs/fit","metadata":{"id":"5nDfJXF7Q4DM","outputId":"4cf4a4a8-c2de-465a-f594-a92bfab3abb2","execution":{"iopub.status.busy":"2022-06-29T18:55:05.397832Z","iopub.execute_input":"2022-06-29T18:55:05.398115Z","iopub.status.idle":"2022-06-29T18:55:08.487414Z","shell.execute_reply.started":"2022-06-29T18:55:05.39808Z","shell.execute_reply":"2022-06-29T18:55:08.486598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"1Jf5zW1mQ4Fj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"LigNxOWEQ4I_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_checkpoint = tf.keras.callbacks.ModelCheckpoint('unet_DB1_multi.hdf5', monitor='loss',verbose=0)\nmodel.fit(data_gen,steps_per_epoch=15,epochs=500,verbose=1, callbacks=[model_checkpoint, tensorboard_callback])","metadata":{"id":"3cC8Y6_hQtzJ","outputId":"8add2187-f191-4418-94b6-522af0c4cbd9","execution":{"iopub.status.busy":"2022-06-29T18:55:12.287621Z","iopub.execute_input":"2022-06-29T18:55:12.287914Z","iopub.status.idle":"2022-06-29T21:10:37.017627Z","shell.execute_reply.started":"2022-06-29T18:55:12.287883Z","shell.execute_reply":"2022-06-29T21:10:37.01693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit()\nprint(history.history.keys())\n\nimport matplotlib.pylab as plt\nfrom matplotlib.pyplot import figure\nfigure(figsize=(8, 6))\nplt.plot(history.history['loss'])\nplt.plot(history.history['dice_coef'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T14:22:14.481347Z","iopub.execute_input":"2022-06-28T14:22:14.481973Z","iopub.status.idle":"2022-06-28T14:22:14.513528Z","shell.execute_reply.started":"2022-06-28T14:22:14.481935Z","shell.execute_reply":"2022-06-28T14:22:14.512198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.models.load_model(\"./model.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T21:41:29.899867Z","iopub.execute_input":"2022-06-29T21:41:29.900239Z","iopub.status.idle":"2022-06-29T21:41:30.825731Z","shell.execute_reply.started":"2022-06-29T21:41:29.900181Z","shell.execute_reply":"2022-06-29T21:41:30.825002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Step 1: Run model on test images and save the images\n#number of test images\nn_i=len(os.listdir('../input/testing2/dataset_final_less_onion/test/images'))\n#Call test generator\ntest_gen = testGenerator('../input/testing2/dataset_final_less_onion/test/images/')\n#Return model outcome for each test image\nresults = model.predict_generator(test_gen,n_i,verbose=1)","metadata":{"id":"kQmhXNC9QzwL","outputId":"5f45c750-052b-4e91-cda2-31db7804c6ab","execution":{"iopub.status.busy":"2022-06-29T21:41:35.111986Z","iopub.execute_input":"2022-06-29T21:41:35.112725Z","iopub.status.idle":"2022-06-29T21:41:39.182474Z","shell.execute_reply.started":"2022-06-29T21:41:35.112686Z","shell.execute_reply":"2022-06-29T21:41:39.18169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(test_gen)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T21:25:37.628771Z","iopub.execute_input":"2022-06-10T21:25:37.629104Z","iopub.status.idle":"2022-06-10T21:25:37.827246Z","shell.execute_reply.started":"2022-06-10T21:25:37.629071Z","shell.execute_reply":"2022-06-10T21:25:37.826238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SaveResultwImage('/kaggle/working/',results)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:12:18.087112Z","iopub.execute_input":"2022-06-28T12:12:18.087611Z","iopub.status.idle":"2022-06-28T12:12:18.112336Z","shell.execute_reply.started":"2022-06-28T12:12:18.087574Z","shell.execute_reply":"2022-06-28T12:12:18.111268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('/kaggle/working/model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-06-29T21:28:27.290545Z","iopub.execute_input":"2022-06-29T21:28:27.290797Z","iopub.status.idle":"2022-06-29T21:28:27.493991Z","shell.execute_reply.started":"2022-06-29T21:28:27.290769Z","shell.execute_reply":"2022-06-29T21:28:27.493241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"././","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SaveResultwImage('./',PATH+'predt/',results)","metadata":{"id":"W3Aw9mGYRW5M","outputId":"8d7adafe-2e60-428e-f0bb-52a43aac3283","execution":{"iopub.status.busy":"2022-06-29T21:42:01.224103Z","iopub.execute_input":"2022-06-29T21:42:01.224739Z","iopub.status.idle":"2022-06-29T21:42:01.268576Z","shell.execute_reply.started":"2022-06-29T21:42:01.224688Z","shell.execute_reply":"2022-06-29T21:42:01.26733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.sum(results))","metadata":{"id":"8txh4w0ARX5l","outputId":"f9cac3e0-4835-4db4-e958-a0dcede233cd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(results[1][:,:,:])\n# plt.savefig(\"results[50].png\")","metadata":{"id":"nvO2tC1ERX7t","outputId":"55eb8239-a27f-4e01-f2f2-47f40a033f0e","execution":{"iopub.status.busy":"2022-06-29T21:53:23.447859Z","iopub.execute_input":"2022-06-29T21:53:23.448135Z","iopub.status.idle":"2022-06-29T21:53:23.676539Z","shell.execute_reply.started":"2022-06-29T21:53:23.448106Z","shell.execute_reply":"2022-06-29T21:53:23.675847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for i in range(157):\nplt.imshow(results[50][:,:,:])\n\nplt.savefig(\"results[50].png\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T21:53:44.841347Z","iopub.execute_input":"2022-06-29T21:53:44.842052Z","iopub.status.idle":"2022-06-29T21:53:45.162616Z","shell.execute_reply.started":"2022-06-29T21:53:44.842015Z","shell.execute_reply":"2022-06-29T21:53:45.161989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(results[51][:,:,:])\n\nplt.savefig(\"results[51].png\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T21:57:37.760505Z","iopub.execute_input":"2022-06-29T21:57:37.760805Z","iopub.status.idle":"2022-06-29T21:57:38.085684Z","shell.execute_reply.started":"2022-06-29T21:57:37.760773Z","shell.execute_reply":"2022-06-29T21:57:38.0849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(results[52][:,:,:])\n\nplt.savefig(\"results[52].png\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T21:57:40.825039Z","iopub.execute_input":"2022-06-29T21:57:40.825322Z","iopub.status.idle":"2022-06-29T21:57:41.137504Z","shell.execute_reply.started":"2022-06-29T21:57:40.825291Z","shell.execute_reply":"2022-06-29T21:57:41.13685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(results[53][:,:,:])\n\nplt.savefig(\"results[53].png\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T21:57:43.673012Z","iopub.execute_input":"2022-06-29T21:57:43.673283Z","iopub.status.idle":"2022-06-29T21:57:43.989555Z","shell.execute_reply.started":"2022-06-29T21:57:43.673255Z","shell.execute_reply":"2022-06-29T21:57:43.988862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(results[54][:,:,:])\n\nplt.savefig(\"results[54].png\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T21:57:46.956804Z","iopub.execute_input":"2022-06-29T21:57:46.957161Z","iopub.status.idle":"2022-06-29T21:57:47.271604Z","shell.execute_reply.started":"2022-06-29T21:57:46.957121Z","shell.execute_reply":"2022-06-29T21:57:47.270855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(results[55][:,:,:])\n\nplt.savefig(\"results[55].png\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T21:57:49.824658Z","iopub.execute_input":"2022-06-29T21:57:49.825227Z","iopub.status.idle":"2022-06-29T21:57:50.13856Z","shell.execute_reply.started":"2022-06-29T21:57:49.825187Z","shell.execute_reply":"2022-06-29T21:57:50.137891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(results[56][:,:,:])\n\nplt.savefig(\"results[56].png\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T21:57:52.870378Z","iopub.execute_input":"2022-06-29T21:57:52.87138Z","iopub.status.idle":"2022-06-29T21:57:53.26779Z","shell.execute_reply.started":"2022-06-29T21:57:52.871337Z","shell.execute_reply":"2022-06-29T21:57:53.267147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(results[57][:,:,:])\n\nplt.savefig(\"results[57].png\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T21:57:56.390436Z","iopub.execute_input":"2022-06-29T21:57:56.390925Z","iopub.status.idle":"2022-06-29T21:57:56.708625Z","shell.execute_reply.started":"2022-06-29T21:57:56.390882Z","shell.execute_reply":"2022-06-29T21:57:56.707863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(results[58][:,:,:])\n\nplt.savefig(\"results[58].png\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T21:57:59.229821Z","iopub.execute_input":"2022-06-29T21:57:59.230099Z","iopub.status.idle":"2022-06-29T21:57:59.543718Z","shell.execute_reply.started":"2022-06-29T21:57:59.230049Z","shell.execute_reply":"2022-06-29T21:57:59.543055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(results[59][:,:,:])\n\nplt.savefig(\"results[59].png\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T21:58:01.976001Z","iopub.execute_input":"2022-06-29T21:58:01.976433Z","iopub.status.idle":"2022-06-29T21:58:02.29438Z","shell.execute_reply.started":"2022-06-29T21:58:01.976386Z","shell.execute_reply":"2022-06-29T21:58:02.293671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(results[60][:,:,:])\n\nplt.savefig(\"results[60].png\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T21:58:05.892531Z","iopub.execute_input":"2022-06-29T21:58:05.892784Z","iopub.status.idle":"2022-06-29T21:58:06.206619Z","shell.execute_reply.started":"2022-06-29T21:58:05.892757Z","shell.execute_reply":"2022-06-29T21:58:06.205852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(results[61][:,:,:])\n\nplt.savefig(\"results[61].png\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T21:58:08.768748Z","iopub.execute_input":"2022-06-29T21:58:08.769526Z","iopub.status.idle":"2022-06-29T21:58:09.082481Z","shell.execute_reply.started":"2022-06-29T21:58:08.769489Z","shell.execute_reply":"2022-06-29T21:58:09.081817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(results[62][:,:,:])\n\nplt.savefig(\"results[62].png\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T21:58:11.953472Z","iopub.execute_input":"2022-06-29T21:58:11.95394Z","iopub.status.idle":"2022-06-29T21:58:12.26555Z","shell.execute_reply.started":"2022-06-29T21:58:11.953898Z","shell.execute_reply":"2022-06-29T21:58:12.264921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(results[63][:,:,:])\n\nplt.savefig(\"results[63].png\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T21:58:14.846328Z","iopub.execute_input":"2022-06-29T21:58:14.846602Z","iopub.status.idle":"2022-06-29T21:58:15.28083Z","shell.execute_reply.started":"2022-06-29T21:58:14.846573Z","shell.execute_reply":"2022-06-29T21:58:15.280016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(results[64][:,:,:])\n\nplt.savefig(\"results[64].png\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T21:58:17.969645Z","iopub.execute_input":"2022-06-29T21:58:17.970377Z","iopub.status.idle":"2022-06-29T21:58:18.283583Z","shell.execute_reply.started":"2022-06-29T21:58:17.970338Z","shell.execute_reply":"2022-06-29T21:58:18.282892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(results[65][:,:,:])\n\nplt.savefig(\"results[65].png\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T21:58:21.766825Z","iopub.execute_input":"2022-06-29T21:58:21.768834Z","iopub.status.idle":"2022-06-29T21:58:22.084568Z","shell.execute_reply.started":"2022-06-29T21:58:21.768798Z","shell.execute_reply":"2022-06-29T21:58:22.083901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(results[66][:,:,:])\n\nplt.savefig(\"results[66].png\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T21:58:25.02139Z","iopub.execute_input":"2022-06-29T21:58:25.021647Z","iopub.status.idle":"2022-06-29T21:58:25.335763Z","shell.execute_reply.started":"2022-06-29T21:58:25.021622Z","shell.execute_reply":"2022-06-29T21:58:25.334881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(results[67][:,:,:])\n\nplt.savefig(\"results[67].png\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T21:58:28.26948Z","iopub.execute_input":"2022-06-29T21:58:28.269737Z","iopub.status.idle":"2022-06-29T21:58:28.585521Z","shell.execute_reply.started":"2022-06-29T21:58:28.269708Z","shell.execute_reply":"2022-06-29T21:58:28.58486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(results[68][:,:,:])\n\nplt.savefig(\"results[68].png\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T21:58:31.554452Z","iopub.execute_input":"2022-06-29T21:58:31.554715Z","iopub.status.idle":"2022-06-29T21:58:31.872528Z","shell.execute_reply.started":"2022-06-29T21:58:31.554687Z","shell.execute_reply":"2022-06-29T21:58:31.871911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(results[69][:,:,:])\n\nplt.savefig(\"results[69].png\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T21:58:34.398528Z","iopub.execute_input":"2022-06-29T21:58:34.399238Z","iopub.status.idle":"2022-06-29T21:58:34.710581Z","shell.execute_reply.started":"2022-06-29T21:58:34.399201Z","shell.execute_reply":"2022-06-29T21:58:34.709912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(results[70][:,:,:])\n\nplt.savefig(\"results[70].png\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T21:58:37.515541Z","iopub.execute_input":"2022-06-29T21:58:37.515839Z","iopub.status.idle":"2022-06-29T21:58:37.832623Z","shell.execute_reply.started":"2022-06-29T21:58:37.51581Z","shell.execute_reply":"2022-06-29T21:58:37.831942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(results[71][:,:,:])\n\nplt.savefig(\"results[71].png\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T21:58:40.726593Z","iopub.execute_input":"2022-06-29T21:58:40.726859Z","iopub.status.idle":"2022-06-29T21:58:41.043986Z","shell.execute_reply.started":"2022-06-29T21:58:40.726828Z","shell.execute_reply":"2022-06-29T21:58:41.043334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(results[72][:,:,:])\n\nplt.savefig(\"results[72].png\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T21:58:43.985991Z","iopub.execute_input":"2022-06-29T21:58:43.98638Z","iopub.status.idle":"2022-06-29T21:58:44.302994Z","shell.execute_reply.started":"2022-06-29T21:58:43.986348Z","shell.execute_reply":"2022-06-29T21:58:44.302314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(results[73][:,:,:])\n\nplt.savefig(\"results[73].png\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T21:58:51.601903Z","iopub.execute_input":"2022-06-29T21:58:51.602586Z","iopub.status.idle":"2022-06-29T21:58:51.913571Z","shell.execute_reply.started":"2022-06-29T21:58:51.60255Z","shell.execute_reply":"2022-06-29T21:58:51.912905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## a = results.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-10T21:29:01.684911Z","iopub.execute_input":"2022-06-10T21:29:01.685166Z","iopub.status.idle":"2022-06-10T21:29:01.688728Z","shell.execute_reply.started":"2022-06-10T21:29:01.685139Z","shell.execute_reply":"2022-06-10T21:29:01.688036Z"}}},{"cell_type":"code","source":"a\n","metadata":{"execution":{"iopub.status.busy":"2022-06-10T21:29:04.645421Z","iopub.execute_input":"2022-06-10T21:29:04.646036Z","iopub.status.idle":"2022-06-10T21:29:04.65197Z","shell.execute_reply.started":"2022-06-10T21:29:04.645997Z","shell.execute_reply":"2022-06-10T21:29:04.651013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plt.imshow(results[26])\nplt.imshow(results[85])\n\n","metadata":{"id":"foKpEkE6RX99","outputId":"82ebe8d0-26c7-4dd8-c461-76bdb2420704","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ANother model\n","metadata":{}},{"cell_type":"code","source":"# predictions\npreds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\npreds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\n# preds_test = model.predict(X_test, verbose=1)\n\n# pred_test_wh = cv2.threshold(preds_test, 128, 255, cv2.THRESH_BINARY)\npreds_train_t = (preds_train > 0.5).astype(np.uint8)\npreds_val_t = (preds_val > 0.5).astype(np.uint8)\n# preds_test_t = (preds_test > 0.5).astype(np.uint8)\n\n\n# Perform a sanity check on some random training samples\nix = random.randint(0, len(preds_train))\nimshow(X_train[ix])\nplt.show()\nimshow(np.squeeze(Y_train[ix]))\nplt.show()\nimshow(np.squeeze(preds_train[ix]))\nplt.show()\n\n\n# Perform a sanity check on some random validation samples\nix = random.randint(0, len(preds_val_t))\nimshow(X_train[int(X_train.shape[0]*0.9):][ix])\nplt.show()\nimshow(np.squeeze(Y_train[int(Y_train.shape[0]*0.9):][ix]))\nplt.show()\nimshow(np.squeeze(preds_val[ix]))\nplt.show()\n","metadata":{"id":"qjiNKzkzRYBZ","outputId":"984895a6-f417-42e2-ef7e-b9ea12b86050","execution":{"iopub.status.busy":"2022-06-29T21:31:43.884633Z","iopub.execute_input":"2022-06-29T21:31:43.884887Z","iopub.status.idle":"2022-06-29T21:31:43.914615Z","shell.execute_reply.started":"2022-06-29T21:31:43.884858Z","shell.execute_reply":"2022-06-29T21:31:43.913739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_input = Input(shape=(512,512 , 3 ))\n\nconv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(img_input)\nconv1 = Dropout(0.2)(conv1)\nconv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\npool1 = MaxPooling2D((2, 2))(conv1)\n\nconv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\nconv2 = Dropout(0.2)(conv2)\nconv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\npool2 = MaxPooling2D((2, 2))(conv2)","metadata":{"id":"7ei6YdltRXD-","execution":{"iopub.status.busy":"2022-06-05T09:29:41.05264Z","iopub.status.idle":"2022-06-05T09:29:41.058656Z","shell.execute_reply.started":"2022-06-05T09:29:41.058413Z","shell.execute_reply":"2022-06-05T09:29:41.05844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\nconv3 = Dropout(0.2)(conv3)\nconv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n\nup1 = concatenate([UpSampling2D((2, 2))(conv3), conv2], axis=-1)\nconv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1)\nconv4 = Dropout(0.2)(conv4)\nconv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv4)\n\nup2 = concatenate([UpSampling2D((2, 2))(conv4), conv1], axis=-1)\nconv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(up2)\nconv5 = Dropout(0.2)(conv5)\nconv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv5)","metadata":{"id":"WKVxBiieRXHY","execution":{"iopub.status.busy":"2022-06-05T09:29:41.060981Z","iopub.status.idle":"2022-06-05T09:29:41.063708Z","shell.execute_reply.started":"2022-06-05T09:29:41.063438Z","shell.execute_reply":"2022-06-05T09:29:41.063466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nimport keras_segmentation \nout = Conv2D( 5, (1, 1) , padding='same')(conv5)\n\nfrom keras_segmentation.models.model_utils import get_segmentation_model\n\n\nmodel = get_segmentation_model(img_input ,  out ) # this would build the segmentation model","metadata":{"execution":{"iopub.status.busy":"2022-06-05T09:29:41.064854Z","iopub.status.idle":"2022-06-05T09:29:41.067238Z","shell.execute_reply.started":"2022-06-05T09:29:41.067008Z","shell.execute_reply":"2022-06-05T09:29:41.067036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install keras-segmentation","metadata":{"execution":{"iopub.status.busy":"2022-06-05T09:29:41.069871Z","iopub.status.idle":"2022-06-05T09:29:41.072338Z","shell.execute_reply.started":"2022-06-05T09:29:41.072109Z","shell.execute_reply":"2022-06-05T09:29:41.072135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import segmentation_models as sm\nsm.set_framework('tf.keras')\n\nsm.framework()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T09:29:41.074702Z","iopub.status.idle":"2022-06-05T09:29:41.075305Z","shell.execute_reply.started":"2022-06-05T09:29:41.075084Z","shell.execute_reply":"2022-06-05T09:29:41.075106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import segmentation_models as sm\nsm.set_framework('tf.keras')\n\nsm.framework()\nfrom keras_segmentation.models.unet import vgg_unet \n\nmodel = vgg_unet(n_classes=5 ,  input_height=512, input_width=512  )","metadata":{"execution":{"iopub.status.busy":"2022-06-05T09:29:41.080215Z","iopub.status.idle":"2022-06-05T09:29:41.080871Z","shell.execute_reply.started":"2022-06-05T09:29:41.080644Z","shell.execute_reply":"2022-06-05T09:29:41.080686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.train( \n    train_images =  \"dataset_path/images_prepped_train/\",\n    train_annotations = \"dataset_path/annotations_prepped_train/\",\n    checkpoints_path = \"checkpoints/vgg_unet_1\" , epochs=5\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T09:29:41.081905Z","iopub.status.idle":"2022-06-05T09:29:41.083826Z","shell.execute_reply.started":"2022-06-05T09:29:41.083534Z","shell.execute_reply":"2022-06-05T09:29:41.08356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"activation='softmax'\n\nLR = 0.0001\noptim = keras.optimizers.Adam(LR)\nmetrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]","metadata":{"execution":{"iopub.status.busy":"2022-06-05T09:29:41.08656Z","iopub.status.idle":"2022-06-05T09:29:41.088573Z","shell.execute_reply.started":"2022-06-05T09:29:41.088298Z","shell.execute_reply":"2022-06-05T09:29:41.08834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_gen1 = preprocess_input1(data_gen)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-05T09:29:41.089843Z","iopub.status.idle":"2022-06-05T09:29:41.094007Z","shell.execute_reply.started":"2022-06-05T09:29:41.093782Z","shell.execute_reply":"2022-06-05T09:29:41.093807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BACKBONE1 = 'resnet34'\npreprocess_input1 = sm.get_preprocessing(BACKBONE1)\n\n# preprocess input\ndata_gen1 = preprocess_input1(data_gen)\n# X_test1 = preprocess_input1(X_test)\n\n# define model\nmodel1 = sm.Unet(BACKBONE1, encoder_weights='imagenet', classes=n_class, activation=activation)\n\n# compile keras model with defined optimozer, loss and metrics\n# model1.compile(optim, total_loss, metrics=metrics)\n\nmodel1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=metrics)\n\nprint(model1.summary())\n\n\nhistory1=model1.fit(data_gen1,\n          batch_size=12, \n          epochs=50,\n          verbose=1\n          )","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:13:04.863591Z","iopub.execute_input":"2022-06-28T12:13:04.864425Z","iopub.status.idle":"2022-06-28T12:13:04.891891Z","shell.execute_reply.started":"2022-06-28T12:13:04.864387Z","shell.execute_reply":"2022-06-28T12:13:04.891116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}